Summary:

type I error:
Generate data under null hypothesis where number of components in mixture model is m=2. Each dataset has 5000 observations with 200 or 400 entries each. We have a total of 12 datasets under the 12 unique combinations of alphas, thetas, and sigmas. For each observation, compute the p-value and encode it with a binary number with 0 being accept null hypothesis and 1 being reject null hypothesis (i.e. accept alternative hypothesis). Then sum the 1’s and divide by m to get the proportion of rejections when the null hypothesis is true i.e. the type I error.

• How many points go into box plot? 
12
• Where did the points come from? 
From each of the 12 datasets, we compute the proportion of rejections when the null hypothesis is true i.e. the type I error. The 12 values go into the box plot. 
• Ef[h(x)], what is h(x) here?
The binary number that encodes the hypothesis testing result.

power of EM test:
Generate data under alternative hypothesis where number of components in mixture model is more than 2.

• What choice of alphas, thetas, and sigmas make it easy to distinguish each component in mixture model? What makes it hard?

• Easy: 
means are far apart relative to standard deviations
small standard deviations
• Hard:
2 or more similar means
1 component infrequent

Reading Questions:
• What are the goals of their simulation study and what are the metrics that they consider in assessing their method?

In this article, the authors presented an effective expectation-maximization (EM) test for testing the null hypothesis of arbitrary order m0 under a finite normal mixture model. To examine the performance of the test on finite sample, they conducted a number of simulation studies.

The goals of the simulation study are to assess the accuracy of the asymptotic approximation in finite samples and to examine the power of the expectation-maximization (EM) test.

The metrics they used to access the hypothesis testing method on the order of the normal mixture model are type I error and power of the EM test.
• What choices did the authors have to make in designing their simulation study? What are the key aspects of the data generating mechanism that likely affect the statistical power of the test?

They chose number of null models to be 12, sample sizes to be 200 and 400, number of repetitions to be 5000, and significance levels to be 5% and 1%.
 
The power of the EM test increases as the sample size increases; also, it increases as the component means under the alternative models become far away from one another.
• Suggest some alternatives to how the authors designed their study. Are there data-generating scenarios that they did not consider that would be useful to consider?

The authors could increase the number of null models as well as sample sizes and replications to achieve higher precision. To do so efficiently, they could run the multiple experiments in parallel. The authors could also use a resampling approach when generating data to control for random differences between the datasets.  
• Give some thoughts on how to set up a simulation study for their problem that uses principles of basic experimental design (see the Unit 10 notes) or if you think it would be difficult, say why.

In the paper, the authors followed the basic steps of a simulation study: specify sample size, distributions, parameters, statistic of interest, etc.; determine what inputs to vary; write code to carry out the individual experiment and return the quantity of interest; for each combination of inputs, repeat the experiment m times; summarize the results for each combination of interest, quantifying simulation uncertainty; and report the results in graphical or tabular form. The authors varied one input variable at a time. Although this makes results easy to interpret, it is inefficient. Instead, they could implement a fractional factorial design by carefully choosing which treatment combinations to omit. The goal is to achieve balance across the levels in a way that allows us to estimate lower level effects (in particular main effects) but not all high-order interactions. 
• Do their figures/tables do a good job of presenting the simulation results and do you have any alternative suggestions for how to do this? Do the authors address the issue of simulation uncertainty/simulation standard errors and/or do they convince the reader they've done enough simulation replications?

The tables and figures presented results clearly. The “simulated Type I errors” figures showed that the observed levels were close to the significance levels that the authors were trying to achieve, particularly when K=3. However, it would make it more clear to the readers the accuracy of the results if the quartiles, minimum, maximum, and median values of the box and whisker plots were labeled. Comparing to the 5% significance level simulations, the values for the 1% significance level simulations seemed to be rather far from what was expected. While this may suggest that the sample sizes should be increased, it could also be due to the fact that the scales between these graphs are different. Keeping the scales constant would eliminate this problem. Although the results come out to be close to what was expected, this paper didn’t totally convince me that there were enough simulation replications since the authors never explained their reasoning behind the choice of values when designing this simulation study. Also, the authors never addressed simulation standard errors. 
• Interpret their tables on power (Tables 4 and 6) - do the results make sense in terms of how the power varies as a function of the data generating mechanism?

Overall, the power of the EM test increases with sample size. Table 4 showed that when the mixing proportions of the 3 models are equal, the power of EM test is greater. However, in the 4 component model, the opposite is true. In Table 6, we can observe that the test has greater power when the component means are further from one another. The above results make sense and are inline with the authors’ conclusions: as sample size increases, power of EM test increases; also, as the component means under the alternative models become further away from one another, the statistical power of the test increases. 
• Discuss the extent to which they follow JASA's guidelines on simulation studies (see the end of the Unit 10 class notes for the JASA guidelines).

JASA’s guidelines on simulation studies states: “Papers reporting results based on computation should provide enough information so that readers can evaluate the quality of the results. Such information includes estimated accuracy of results, as well as descriptions of pseudorandom-number generators, numerical algorithms, computers, programming languages, and major software components that were used.” In this study, the authors used R to implement the EM test and made the supplementary materials available online, which means that the results of this study should be reproducible by the reader. Although they did not elaborate on the details of the simulation process, the tables of simulated Type I errors and the powers of the test can help readers to evaluate the quality of their results. 